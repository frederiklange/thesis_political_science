{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presprocessing Speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading pickle\n",
    "speeches = pd.read_pickle('/Users/frederiklange/Documents/Statskundskab /Kandidat/Speciale/kode/data/ft_speeches.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First five rows\n",
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "speeches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches.loc[speeches['name']=='Uffe Elbæk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeches per year: Before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "speeches_yearly = speeches.groupby(speeches['date'].dt.year)['text'].agg(['count'])\n",
    "\n",
    "# Checking grouped data\n",
    "speeches_yearly\n",
    "\n",
    "# Adding year column\n",
    "speeches_yearly['year'] = speeches_yearly.index\n",
    "\n",
    "# Dropping wrong year\n",
    "speeches_yearly = speeches_yearly[speeches_yearly['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "speeches_yearly['year'] = speeches_yearly['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(speeches_yearly).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('count', title='Antal taler'),\n",
    "    tooltip = 'count'\n",
    ").interactive().configure_mark(opacity=0.8,color='#00BFA5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words per speech per year: Before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column with number of words per speech\n",
    "speeches['no_words'] = speeches['text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "speeches_yearly_no_words = speeches.groupby(speeches['date'].dt.year)['no_words'].agg(['mean'])\n",
    "\n",
    "# Checking grouped data\n",
    "speeches_yearly_no_words\n",
    "\n",
    "# Adding year column\n",
    "speeches_yearly_no_words['year'] = speeches_yearly_no_words.index\n",
    "\n",
    "# Dropping wrong year\n",
    "speeches_yearly_no_words = speeches_yearly_no_words[speeches_yearly_no_words['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "speeches_yearly_no_words['year'] = speeches_yearly_no_words['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(speeches_yearly_no_words).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('mean', title='Antal ord'),\n",
    "    tooltip = 'mean'\n",
    ").interactive().configure_mark(opacity=0.8,color='#00BFA5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesseing speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Drop taler af formænd og næstformænd, som er formelle og faste (X)\n",
    "2. Hvilke partier skal indgå? Dem som har eksisteret i tidsperioden (X)\n",
    "3. Ekskludere partiuafhængige (X)\n",
    "4. Drop alt tekst med navne og ministertitler (X)\n",
    "5. Stemme tekst\n",
    "6. Smid taler ud, der ikke har et normalt år (X)\n",
    "7. Fjern punctuation mm.\n",
    "8. Fjern stopord\n",
    "9. Behold ord, der sagt mindst x antal gange\n",
    "10. Fjern procedurale ord (X)\n",
    "11. uni, bi and trigrams\n",
    "12. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing non-party members and ft-presidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting parties and roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parties\n",
    "speeches_parties_yearly = speeches['date'].groupby([speeches.date.dt.year, speeches.party]).agg('count')\n",
    "\n",
    "# Unstacking parties\n",
    "speeches_parties_yearly_table = speeches_parties_yearly.unstack('party')\n",
    "\n",
    "# Printing\n",
    "speeches_parties_yearly_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speeches per party\n",
    "speeches['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of speeches before removal of small parties\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Kristeligt Folkeparti til Kristendemokraterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming kristendemokraterne\n",
    "speeches['party'] = speeches['party'].replace({'KRF': 'KD'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing smaller parties and non-party-members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing parties\n",
    "parties_to_remove = ['TS',\n",
    "                     'PØU',\n",
    "                     'DMI',\n",
    "                     '4/10 05',\n",
    "                     'RY',\n",
    "                     'FF',\n",
    "                     'FÆR',\n",
    "                     'NQ',\n",
    "                     'SP',\n",
    "                     'T',\n",
    "                     'TP',\n",
    "                     'TF',\n",
    "                     'JF',\n",
    "                     'SIU',\n",
    "                     'Pause',\n",
    "                     'UFG',\n",
    "                     'UP',\n",
    "                     'IA',\n",
    "                     'REG',\n",
    "                     'MødeSlut',\n",
    "                     'FRI',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping over roles\n",
    "for party in parties_to_remove:\n",
    "    speeches =  speeches[speeches['party']!=party]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of speeches before removal of small parties\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing formal speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting roles\n",
    "speeches[speeches['role'].str.contains('formand', na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing speakers\n",
    "roles_to_remove = ['formand',\n",
    "                   'aldersformanden',\n",
    "                   'MødeSlut',\n",
    "                   'Pause',\n",
    "                   'Formanden ■',\n",
    "                   '.. Formanden',\n",
    "                   'Formanden v:v,',\n",
    "                   'Formanden,',\n",
    "                   'Formanden ^',\n",
    "                   \"Formanden: v>'<\",\n",
    "                   \"Formanden i' -k: ■;; .'.vvv.y\",\n",
    "                   '\", Formanden',\n",
    "                   'Formanden v',\n",
    "                   'Formanden l-',\n",
    "                   'Formanden \" s',\n",
    "                   'Formanden I.',\n",
    "                   'Formanden ;',\n",
    "                   'Formanden —',\n",
    "                   'Formanden >■> •:',\n",
    "                   'Formanden 7',\n",
    "                   'Formanden :',\n",
    "                   'Formanden ^ ^',\n",
    "                   'Formanden, ..--r-',\n",
    "                   'Formanden i/i--:',\n",
    "                   'Formanden r',\n",
    "                   'Formanden -',\n",
    "                   'Formanden i,: m',\n",
    "                   \"Formanden'\",\n",
    "                   'Formanden; ^',\n",
    "                   'Formanden .ri/.r.-!-',\n",
    "                   'v Formanden',\n",
    "                   'Formanden -r.i, ..r.-?;■■■',\n",
    "                   'Formanden .',\n",
    "                   'Formanden „ _..s'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping over roles\n",
    "for role in roles_to_remove:\n",
    "    speeches =  speeches[speeches['role']!=role] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of speeches before removal of formal speekers\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing formal text bites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan texts\n",
    "nan_texts = ['Talen er under udarbejdelse)',\n",
    "             'Ordfører (Talen er under udarbejdelse)',\n",
    "             '(Spørgsmålet er udgået, da det er taget tilbage af spørgeren).',\n",
    "             'Finansministeren (Talen er under udarbejdelse)',\n",
    "             '(Spørgsmålet er udgået af dagsordenen).',\n",
    "             '(Punktet er udgået af dagsordenen).',\n",
    "             'Ordfører (Talen er under udarbejdelse) (Talen er under udarbejdelse)',\n",
    "             'Ja.',\n",
    "             '(Spørgsmålet er udgået under henvisning til Folketingets forretningsordens § 20, stk. 5).',\n",
    "             '(Spørgsmålet er overgået til skriftlig besvarelse).',\n",
    "             '(Spørgsmålet er udgået efter aftale mellem ministeren og spørgeren).',\n",
    "             'Nej.',\n",
    "             'Jo.',\n",
    "             'Ordfører for forslagsstillerne (Talen er under udarbejdelse)',\n",
    "             '(Talen er under udarbejdelse) (Talen er under udarbejdelse) (Talen er under udarbejdelse)',\n",
    "             'Selv tak.',\n",
    "             'Jeg har ikke flere spørgsmål.',\n",
    "             'Ordfører Liberal Alliance støtter også lovforslaget.',\n",
    "             '(Spørgsmålet er udgået på grund af lydtekniske problemer).',\n",
    "             '(Talen er under udarbejdelse) (Talen er under udarbejdelse)',\n",
    "             'Tak for det.',\n",
    "             'Ja, det kan jeg bekræfte.',\n",
    "             'Det er noteret.',\n",
    "             '(Talen er under udarbejdelse)',\n",
    "             'Privatist (Talen er under udarbejdelse)',\n",
    "             'Ordfører for forespørgerne (Talen er under udarbejdelse)',\n",
    "             'Ordfører for forespørgerne (Talen er under udarbejdelse) (Talen er under udarbejdelse)',\n",
    "             'Finansministeren (Talen er under udarbejdelse) (Talen er under udarbejdelse) (Talen er under udarbejdelse) (Talen er under udarbejdelse) (Talen er under udarbejdelse) (Talen er under udarbejdelse)'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making speeches to strings\n",
    "speeches['text'] = speeches['text'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping over texts\n",
    "for nan_text in nan_texts:\n",
    "    speeches = speeches[speeches['text']!=nan_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of speeches before removal of formal text bites\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing NA dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Nas for date\n",
    "speeches['date'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating nan values\n",
    "speeches['date'].replace([\"NaN\", 'NaT'], np.nan, inplace = True)\n",
    "\n",
    "# Subsetting to remove NA's\n",
    "speeches = speeches[speeches['date'].isna()==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speeches after NA date\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing NA parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting parties\n",
    "na_parties_df = speeches[speeches['party'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique names\n",
    "na_parties_df['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_parties_df['name'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with no parties\n",
    "no_party = {'Lars Løkke Rasmussen': 'V',\n",
    " 'Eva Kjer Hansen': 'V',\n",
    " 'Claus Hjort Frederiksen': 'V',\n",
    " 'Troels Lund Poulsen': 'V',\n",
    " 'Karen Ellemann': 'V',\n",
    " 'Inger Støjberg': 'V',\n",
    " 'Birthe Rønn Hornbech': 'V',\n",
    " 'Helge Sander': 'V',\n",
    " 'Brian Mikkelsen': 'KF',\n",
    " 'Lars Barfoed': 'KF',\n",
    " 'Kristian Jensen': 'V',\n",
    " 'Søren Gade': 'V',\n",
    " 'Carina Christensen': 'KF',\n",
    " 'Bertel Haarder': 'V',\n",
    " 'Lene Espersen': 'KF',\n",
    " 'Per Stig Møller': 'KF',\n",
    " 'Connie Hedegaard': 'KF',\n",
    " 'Jakob Axel Nielsen': 'KF',\n",
    " 'Lykke Friis': 'V', \n",
    " 'Ulla Tørnæs': 'V',\n",
    " 'Gitte Lillelund Bech': 'V',\n",
    " 'Benedikte Kiær': 'KF',\n",
    " 'Tina Nedergaard': 'V',\n",
    " 'Charlotte Sahl-Madsen': 'KF',\n",
    " 'Henrik Høegh': 'V',\n",
    " 'Hans Christian Schmidt': 'V',\n",
    " 'Søren Pind': 'V',\n",
    " 'Peter Christensen': 'V',\n",
    " 'Thor Möger Pedersen': 'S',\n",
    " 'Martin Lidegaard': 'RV',\n",
    " 'Karen Hækkerup': 'S',\n",
    " 'Bjarne Corydon': 'S',\n",
    " 'Henrik Dam Kristensen': 'S',\n",
    " 'Mette Frederiksen': 'S',\n",
    " 'Astrid Krag': 'S',\n",
    " 'Manu Sareen': 'RV',\n",
    " 'Christian Friis Bach': 'S',\n",
    " 'Uffe Elbæk': 'RV',\n",
    " 'Ole Sohn': 'S',\n",
    " 'Morten Bødskov': 'S',\n",
    " 'Helle Thorning-Schmidt': 'S',\n",
    " 'Margrethe Vestager': 'RV',\n",
    " 'Villy Søvndal': 'SF',\n",
    " 'Morten Østergaard': 'RV',\n",
    " 'Carsten Hansen': 'S',\n",
    " 'Christine Antorini': 'S',\n",
    " 'Pia Olsen Dyhr': 'SF',\n",
    " 'Ida Auken': 'RV', \n",
    " 'Mette Gjerskov': 'S',\n",
    " 'Nicolai Wammen': 'S',\n",
    " 'Nick Hækkerup': 'S',\n",
    " 'Annette Vilhelmsen': 'SF',\n",
    " 'Holger K. Nielsen': 'SF',\n",
    " 'Marianne Jelved': 'RV',\n",
    " 'Henrik Sass Larsen': 'S',\n",
    " 'Rasmus Helveg Petersen': 'RV',\n",
    " 'Jonas Dahl': 'SF',\n",
    " 'Dan Jørgensen': 'S',\n",
    " 'Sofie Carsten Nielsen': 'RV',\n",
    " 'Magnus Heunicke': 'S',\n",
    " 'Kirsten Brosbøl': 'S',\n",
    " 'Mogens Jensen': 'S',\n",
    " 'Benny Engelbrecht': 'S',\n",
    " 'Karsten Lauritzen': 'V',\n",
    " 'Jørn Neergaard Larsen': 'V',\n",
    " 'Ellen Trane Nørby': 'V',\n",
    " 'Sophie Løhde': 'V',\n",
    " 'Esben Lunde Larsen': 'V',\n",
    " 'Lars Christian Lilleholt': 'V',\n",
    " 'Mai Mercado': 'KF',\n",
    " 'Simon Emil Ammitzbøll': 'KF',\n",
    " 'Søren Pape Poulsen': 'KF',\n",
    " 'Merete Riisager': 'LA',\n",
    " 'Ole Birk Olesen': 'LA',\n",
    " 'Thyra Frank': 'LA',\n",
    " 'Anders Samuelsen': 'LA',\n",
    " 'Mette Bock': 'LA',\n",
    " 'Simon Emil Ammitzbøll-Bille': 'LA',\n",
    " 'Jakob Ellemann-Jensen': 'V',\n",
    " 'Tommy Ahlers': 'V',\n",
    " 'Rasmus Jarlov': 'KF',\n",
    " 'Kaare Dybvad': 'S',\n",
    " 'Peter Hummelgaard Thomsen': 'S',\n",
    " 'Jeppe Kofod': 'S',\n",
    " 'Pernille Rosenkrantz-Theil': 'S',\n",
    " 'Ane Halsboe-Jørgensen': 'S',\n",
    " 'Simon Kollerup': 'S',\n",
    " 'Mattias Tesfaye': 'S',\n",
    " 'Lea Wermelin': 'S',\n",
    " 'Trine Bramsen': 'S',\n",
    " 'Rasmus Prehn': 'S',\n",
    " 'Peter Hummelgaard': 'S',\n",
    " 'Kaare Dybvad Bek': 'S',\n",
    " 'Joy Mogensen': 'S',\n",
    " 'Flemming Møller Mortensen': 'S'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace party values\n",
    "for key, value in no_party.items():\n",
    "    speeches.loc[speeches.name == key, 'party'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efter erstatning partier\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting parties\n",
    "na_role_df = speeches[speeches['role'].isna()]\n",
    "na_role_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NA dates\n",
    "speeches = speeches[speeches['role'].isna()==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of speeches after role is removes\n",
    "speeches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA navne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speeches[speeches.name.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating full text version of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_temp = speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_temp['full_text'] = speeches['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove names and roles from speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating df of roles\n",
    "roles = speeches.role.value_counts().rename_axis('unique_values').reset_index(name='counts')\n",
    "\n",
    "# Creating list of roles\n",
    "roles = roles['unique_values']\n",
    "\n",
    "# Creating list of names\n",
    "names = speeches['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating to one list\n",
    "roles_names = list(roles) + list(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_names = list(map(str, roles_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_names_lower = [x.lower() for x in roles_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a space in front of each word\n",
    "roles_names = [f' {x} ' for x in roles_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "# Loop over words and remove from all speeches\n",
    "for name_role in roles_names:\n",
    "    x += 1\n",
    "    try:\n",
    "        speeches['text'] = speeches['text'].str.replace(name_role, '  ')\n",
    "    except:\n",
    "        pass\n",
    "    print(f'done with {x}/2500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches[\"text\"] = speeches[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove parties and shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties_short = [' socialedemokratiet ',\n",
    "                 ' socialedemokraterne ',\n",
    "                 ' socialedemokraternes ',\n",
    "                 ' socialdemokratiets ',\n",
    "                 ' s ',\n",
    "                 ' socialistiske folkeparti ',\n",
    "                 ' sf ',\n",
    "                 ' sfs ',\n",
    "                 ' det socialistiske folkeparti ',\n",
    "                 ' socialistisk folkeparti ',\n",
    "                 ' socialtisk folkepartis ',\n",
    "                 ' enhedslisten ',\n",
    "                 ' enhedslistens ',\n",
    "                 ' el ',\n",
    "                 ' els ',\n",
    "                 ' e ',\n",
    "                 ' det radikale venstre ',\n",
    "                 ' radikale venstre ',\n",
    "                 ' radikale venstres ',\n",
    "                 ' det radikale ventres ',\n",
    "                 ' rv ',\n",
    "                 ' rvs ',\n",
    "                 ' venstre ',\n",
    "                 ' v ',\n",
    "                 ' vs ',\n",
    "                 ' venstres ',\n",
    "                 ' df ',\n",
    "                 ' dfs ',\n",
    "                 ' dansk folkeparti ',\n",
    "                 ' dansk folkepartis ',\n",
    "                 ' konservative ',\n",
    "                 ' det konservative folkeparti ',\n",
    "                 ' konsevatives ',\n",
    "                 ' det konservative folkepartis ',\n",
    "                 ' k ',\n",
    "                 ' ks ',\n",
    "                 ' la ',\n",
    "                 ' las ',\n",
    "                 ' liberal alliance ',\n",
    "                 ' liberal alliances ',\n",
    "                 ' fremskridtspartiet ',\n",
    "                 ' fremskridtspartiets',\n",
    "                 ' fp ',\n",
    "                 ' fps ',\n",
    "                 ' kristendemokraterne ',\n",
    "                 ' kristendermokraternes ',\n",
    "                 ' kristeligt folkeparti',\n",
    "                 ' kristeligt folkepartis ',\n",
    "                 ' alternativet ',\n",
    "                 ' alternativets ',\n",
    "                 ' centrumdemokraterne ',\n",
    "                 ' ventrumdemokraternes ',\n",
    "                 ' nye borgerlige ',\n",
    "                 ' nye borgerliges ',\n",
    "                 ' nb ',\n",
    "                 ' nbs ',\n",
    "                 ' rød blok ',\n",
    "                 ' blå blok ',\n",
    "                 ' oppositionen ',\n",
    "                 ' regeringen ',\n",
    "                 ' de blå ',\n",
    "                 ' de røde '\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches['text'].str.contains(' det radikale venstre ').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = speeches\n",
    "test['text'] = speeches['text'].str.replace(' det radikale venstre ', ' ')\n",
    "test['text'].str.contains(' det radikale venstre ').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "# Loop over words and remove from all speeches\n",
    "for party in parties_short:\n",
    "    x += 1\n",
    "    try:\n",
    "        speeches['text'] = speeches['text'].str.replace(party, '  ')\n",
    "    except:\n",
    "        pass\n",
    "    print(f'done with {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Dataframe before text as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking entire df\n",
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data for navne, som i stedet er angivet som rolle\n",
    "speeches[speeches['name'].isna()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text as data: presprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/frederiklange/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/frederiklange/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/frederiklange/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# for vectorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import scipy.sparse\n",
    "\n",
    "#other packages\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import SnowballStemmer  \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = pd.read_pickle(\"all_speeches.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NWG0g5eHWAJO"
   },
   "outputs": [],
   "source": [
    "# Punctuation that needs to be removed\n",
    "PUNCT_TO_REMOVE = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sl70XsnwWAJP"
   },
   "outputs": [],
   "source": [
    "# Creating function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vfdAmd-FWAJP",
    "outputId": "67ec993d-5931-437a-9e6a-3375701b7c73"
   },
   "outputs": [],
   "source": [
    "# Removing punctuation\n",
    "speeches[\"text\"] = speeches[\"text\"].apply(lambda text: remove_punctuation(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_names_roles = list(roles_names_lower) + list(parties_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_names_roles = [word.strip() for word in party_names_roles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LN7Yrr5CWAJR"
   },
   "outputs": [],
   "source": [
    "# Creating function to remove stopwords\n",
    "def remove_parties_names_roles(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in party_names_roles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSLnl7zPWAJR",
    "outputId": "505f7633-eca5-4d26-c849-546d1f6be90d"
   },
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "speeches[\"text\"] = speeches[\"text\"].apply(lambda text: remove_parties_names_roles(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = ['ad',\n",
    "'af',\n",
    "'aldrig',\n",
    "'alene',\n",
    "'alle',\n",
    "'allerede',\n",
    "'alligevel',\n",
    "'alt',\n",
    "'altid',\n",
    "'anden',\n",
    "'andet',\n",
    "'andre',\n",
    "'at',\n",
    "'bag',\n",
    "'bare',\n",
    "'begge',\n",
    "'bl.a.',\n",
    "'blandt',\n",
    "'blev',\n",
    "'blive',\n",
    "'bliver',\n",
    "'burde',\n",
    "'bør',\n",
    "'ca.',\n",
    "'da',\n",
    "'de',\n",
    "'dem',\n",
    "'den',\n",
    "'denne',\n",
    "'dens',\n",
    "'der',\n",
    "'derefter',\n",
    "'deres',\n",
    "'derfor',\n",
    "'derfra',\n",
    "'deri',\n",
    "'dermed',\n",
    "'derpå',\n",
    "'derved',\n",
    "'det',\n",
    "'dette',\n",
    "'dig',\n",
    "'din',\n",
    "'dine',\n",
    "'disse',\n",
    "'dit',\n",
    "'dog',\n",
    "'du',\n",
    "'efter',\n",
    "'egen',\n",
    "'ej',\n",
    "'eller',\n",
    "'ellers',\n",
    "'en',\n",
    "'end',\n",
    "'endnu',\n",
    "'ene',\n",
    "'eneste',\n",
    "'enhver',\n",
    "'ens',\n",
    "'enten',\n",
    "'er',\n",
    "'et',\n",
    "'f.eks.',\n",
    "'far',\n",
    "'fem',\n",
    "'fik',\n",
    "'fire',\n",
    "'flere',\n",
    "'flest',\n",
    "'fleste',\n",
    "'for',\n",
    "'foran',\n",
    "'fordi',\n",
    "'forrige',\n",
    "'fra',\n",
    "'fx',\n",
    "'få',\n",
    "'får',\n",
    "'før',\n",
    "'først',\n",
    "'gennem',\n",
    "'gjorde',\n",
    "'gjort',\n",
    "'god',\n",
    "'godt',\n",
    "'gør',\n",
    "'gøre',\n",
    "'gørende',\n",
    "'ham',\n",
    "'han',\n",
    "'hans',\n",
    "'har',\n",
    "'havde',\n",
    "'have',\n",
    "'hej',\n",
    "'hel',\n",
    "'heller',\n",
    "'helt',\n",
    "'hen',\n",
    "'hende',\n",
    "'hendes',\n",
    "'henover',\n",
    "'her',\n",
    "'herefter',\n",
    "'heri',\n",
    "'hermed',\n",
    "'herpå',\n",
    "'hos',\n",
    "'hun',\n",
    "'hvad',\n",
    "'hvem',\n",
    "'hver',\n",
    "'hvilke',\n",
    "'hvilken',\n",
    "'hvilkes',\n",
    "'hvis',\n",
    "'hvor',\n",
    "'hvordan',\n",
    "'hvorefter',\n",
    "'hvorfor',\n",
    "'hvorfra',\n",
    "'hvorhen',\n",
    "'hvori',\n",
    "'hvorimod',\n",
    "'hvornår',\n",
    "'hvorved',\n",
    "'i',\n",
    "'igen',\n",
    "'igennem',\n",
    "'ikke',\n",
    "'imellem',\n",
    "'imens',\n",
    "'imod',\n",
    "'ind',\n",
    "'indtil',\n",
    "'ingen',\n",
    "'intet',\n",
    "'ja',\n",
    "'jeg',\n",
    "'jer',\n",
    "'jeres',\n",
    "'jo',\n",
    "'kan',\n",
    "'kom',\n",
    "'komme',\n",
    "'kommer',\n",
    "'kun',\n",
    "'kunne',\n",
    "'lad',\n",
    "'langs',\n",
    "'lav',\n",
    "'lave',\n",
    "'lavet',\n",
    "'lidt',\n",
    "'lige',\n",
    "'ligesom',\n",
    "'lille',\n",
    "'længere',\n",
    "'man',\n",
    "'mand',\n",
    "'mange',\n",
    "'med',\n",
    "'meget',\n",
    "'mellem',\n",
    "'men',\n",
    "'mens',\n",
    "'mere',\n",
    "'mest',\n",
    "'mig',\n",
    "'min',\n",
    "'mindre',\n",
    "'mindst',\n",
    "'mine',\n",
    "'mit',\n",
    "'mod',\n",
    "'må',\n",
    "'måske',\n",
    "'ned',\n",
    "'nej',\n",
    "'nemlig',\n",
    "'ni',\n",
    "'nogen',\n",
    "'nogensinde',\n",
    "'noget',\n",
    "'nogle',\n",
    "'nok',\n",
    "'nu',\n",
    "'ny',\n",
    "'nyt',\n",
    "'når',\n",
    "'nær',\n",
    "'næste',\n",
    "'næsten',\n",
    "'og',\n",
    "'også',\n",
    "'okay',\n",
    "'om',\n",
    "'omkring',\n",
    "'op',\n",
    "'ordfører',\n",
    "'ordføreren',             \n",
    "'os',\n",
    "'otte',\n",
    "'over',\n",
    "'overalt',\n",
    "'pga.',\n",
    "'på',\n",
    "'samme',\n",
    "'sammen',\n",
    "'se',\n",
    "'seks',\n",
    "'selv',\n",
    "'selvom',\n",
    "'senere',\n",
    "'ser',\n",
    "'ses',\n",
    "'siden',\n",
    "'sig',\n",
    "'sige',\n",
    "'sin',\n",
    "'sine',\n",
    "'sit',\n",
    "'skal',\n",
    "'skulle',\n",
    "'som',\n",
    "'stadig',\n",
    "'stor',\n",
    "'store',\n",
    "'synes',\n",
    "'syntes',\n",
    "'syv',\n",
    "'så',\n",
    "'sådan',\n",
    "'således',\n",
    "'tag',\n",
    "'tage',\n",
    "'tak',\n",
    "'temmelig',\n",
    "'thi',\n",
    "'ti',\n",
    "'tidligere',\n",
    "'til',\n",
    "'tilbage',\n",
    "'tit',\n",
    "'to',\n",
    "'tre',\n",
    "'ud',\n",
    "'uden',\n",
    "'udover',\n",
    "'under',\n",
    "'undtagen',\n",
    "'var',\n",
    "'ved',\n",
    "'vi',\n",
    "'via',\n",
    "'vil',\n",
    "'ville',\n",
    "'vor',\n",
    "'vore',\n",
    "'vores',\n",
    "'vær',\n",
    "'være',\n",
    "'været',\n",
    "'øvrig',\n",
    "'hr',\n",
    "'fru',\n",
    "'minist',\n",
    "'altså',\n",
    "'gerne',\n",
    "'men',\n",
    "'sig',\n",
    "'tror',\n",
    "'giv',\n",
    "'går',\n",
    "'tag',\n",
    "'find',\n",
    "'sid',\n",
    "'brug',\n",
    "'selvfølgelig',\n",
    "'rigtig',\n",
    "'tror',\n",
    "'spørgsmål',\n",
    "'forslag',\n",
    "'år',\n",
    "'muligvis',\n",
    "'kr',\n",
    "'ind',\n",
    "'ønske',\n",
    "'spørge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LN7Yrr5CWAJR"
   },
   "outputs": [],
   "source": [
    "# Creating function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kSLnl7zPWAJR",
    "outputId": "505f7633-eca5-4d26-c849-546d1f6be90d"
   },
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "speeches[\"text\"] = speeches[\"text\"].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "brXrK9i4WAJZ"
   },
   "outputs": [],
   "source": [
    "# Defining Stemmer\n",
    "stemmer = SnowballStemmer(\"danish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GSH7j4_kWAJa"
   },
   "outputs": [],
   "source": [
    "# Creating stemming function\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p8VgpXb9WAJa",
    "outputId": "67a9e99c-a4b5-4426-e127-bf9ab0ba545f"
   },
   "outputs": [],
   "source": [
    "# stemming words\n",
    "speeches[\"text\"] = speeches[\"text\"].apply(lambda text: stem_words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a1da28347335>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  speeches['text'] = speeches['text'].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "# Removing numbers\n",
    "speeches['text'] = speeches['text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          verd fjor europa anderled folketingsår indled ...\n",
       "1          står midt betydningsfuld forjæt forandring øst...\n",
       "2          men høj grad land tag medansvar verdensudvikli...\n",
       "3          beundringsværd energi viljestyrk nye regering ...\n",
       "4          afgør europa fremtid lyk nye tid baltikumpolit...\n",
       "                                 ...                        \n",
       "1819742    forkert del stem person grundlov spæd barndom ...\n",
       "1819743    spørgsmål giv anledning oplev stort problem in...\n",
       "1819744    retssikkerhedsmæs korrek sæt grundlov kraft si...\n",
       "1819745    følg mærk idé sæt grundlov kraft begynd regul ...\n",
       "1819746    interessant diskussion rejs står grundlov skat...\n",
       "Name: text, Length: 1819747, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches.to_pickle('', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          17\n",
       "1          34\n",
       "2          29\n",
       "3          32\n",
       "4          23\n",
       "           ..\n",
       "1819742    17\n",
       "1819743    35\n",
       "1819744    20\n",
       "1819745    10\n",
       "1819746    23\n",
       "Name: no_words_after, Length: 1819747, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches['no_words_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_2 = pd.read_pickle('all_speeches.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches['full_text'] = speeches_2['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating group variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible parties\n",
    "parties = speeches['party'].unique()\n",
    "\n",
    "# Print parties\n",
    "parties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blokke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blokke\n",
    "red = ['S', 'RV', 'SF', 'EL', 'ALT']\n",
    "blue = ['KF', 'V', 'CD', 'FP', 'KD', 'DF', 'LA', 'NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bloc variable\n",
    "speeches.loc[speeches['party'].isin(red), \"blok\"] = 0\n",
    "speeches.loc[speeches['party'].isin(blue), \"blok\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parti mod anden blok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making seperate dataset for each bloc\n",
    "red_speeches = speeches.loc[speeches['blok'] == 0]\n",
    "blue_speeches = speeches.loc[speeches['blok'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing dfs\n",
    "print(red_speeches.shape)\n",
    "print(blue_speeches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rød med dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod egen blok\n",
    "red_dummies = pd.get_dummies(red_speeches[\"party\"])\n",
    "\n",
    "# Adding dummies to df\n",
    "red_speeches = red_speeches.join(red_dummies)\n",
    "\n",
    "# Checking new DF\n",
    "red_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blå med dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parti mod egen blok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod egen blok\n",
    "blue_dummies = pd.get_dummies(blue_speeches[\"party\"])\n",
    "\n",
    "# Adding dummies to df\n",
    "blue_speeches = blue_speeches.join(blue_dummies)\n",
    "\n",
    "# Checking new DF\n",
    "blue_speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parti mod resten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod egen resten\n",
    "dummies = pd.get_dummies(speeches[\"party\"])\n",
    "\n",
    "# Adding dummies to df\n",
    "speeches = speeches.join(dummies)\n",
    "\n",
    "# Checking new DF\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number words after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches['no_words_after'] = speeches['text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyYSKjrmWAJe"
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2), min_df=200, max_df=0.50)\n",
    "\n",
    "# Transform\n",
    "doc_vec = vectorizer.fit_transform(speeches[\"text\"])\n",
    "\n",
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tfidf\n",
    "tfidf = pd.DataFrame.sparse.from_spmatrix(doc_vec, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking tdidf\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAJ92LIHWAJf"
   },
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "speeches.reset_index(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "tfidf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZw67aFEWAJg"
   },
   "outputs": [],
   "source": [
    "# Merging the two datasets\n",
    "speeches_tfidf = pd.concat([speeches, tfidf], axis=1)\n",
    "\n",
    "# Dropping index column\n",
    "del speeches_tfidf['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df\n",
    "speeches_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle\n",
    "speeches_tfidf.to_pickle(\"all_speeches.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyYSKjrmWAJe"
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2), min_df=200, max_df=0.50)\n",
    "\n",
    "# Transform\n",
    "doc_vec = vectorizer.fit_transform(red_speeches[\"text\"])\n",
    "\n",
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tfidf\n",
    "red_tfidf = pd.DataFrame.sparse.from_spmatrix(doc_vec, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking tdidf\n",
    "red_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAJ92LIHWAJf"
   },
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "red_speeches.reset_index(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "red_tfidf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZw67aFEWAJg"
   },
   "outputs": [],
   "source": [
    "# Merging the two datasets\n",
    "red_speeches_tfidf = pd.concat([red_speeches, red_tfidf], axis=1)\n",
    "\n",
    "# Dropping index column\n",
    "del red_speeches_tfidf['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df\n",
    "red_speeches_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle\n",
    "red_speeches_tfidf.to_pickle(\"red_speeches.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyYSKjrmWAJe"
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2), min_df=200, max_df=0.50)\n",
    "\n",
    "# Transform\n",
    "doc_vec = vectorizer.fit_transform(blue_speeches[\"text\"])\n",
    "\n",
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tfidf\n",
    "blue_tfidf = pd.DataFrame.sparse.from_spmatrix(doc_vec, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking tdidf\n",
    "blue_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAJ92LIHWAJf"
   },
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "blue_speeches.reset_index(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "blue_tfidf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZw67aFEWAJg"
   },
   "outputs": [],
   "source": [
    "# Merging the two datasets\n",
    "blue_speeches_tfidf = pd.concat([blue_speeches, blue_tfidf], axis=1)\n",
    "\n",
    "# Dropping index column\n",
    "del blue_speeches_tfidf['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df\n",
    "blue_speeches_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle\n",
    "blue_speeches_tfidf.to_pickle(\"blue_speeches.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "speeches_yearly = speeches.groupby(speeches['date'].dt.year)['text'].agg(['count'])\n",
    "\n",
    "# Checking grouped data\n",
    "speeches_yearly\n",
    "\n",
    "# Adding year column\n",
    "speeches_yearly['year'] = speeches_yearly.index\n",
    "\n",
    "# Dropping wrong year\n",
    "speeches_yearly = speeches_yearly[speeches_yearly['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "speeches_yearly['year'] = speeches_yearly['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(speeches_yearly).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('count', title='Antal taler'),\n",
    "    tooltip = 'count'\n",
    ").interactive().configure_mark(opacity=0.8,color='#00BFA5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words per speech per year: Before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column with number of words per speech\n",
    "speeches['no_words'] = speeches['text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "speeches_yearly_no_words = speeches.groupby(speeches['date'].dt.year)['no_words_after'].agg(['mean'])\n",
    "\n",
    "# Checking grouped data\n",
    "speeches_yearly_no_words\n",
    "\n",
    "# Adding year column\n",
    "speeches_yearly_no_words['year'] = speeches_yearly_no_words.index\n",
    "\n",
    "# Dropping wrong year\n",
    "speeches_yearly_no_words = speeches_yearly_no_words[speeches_yearly_no_words['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "speeches_yearly_no_words['year'] = speeches_yearly_no_words['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(speeches_yearly_no_words).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('mean', title='Antal ord'),\n",
    "    tooltip = 'mean'\n",
    ").interactive().configure_mark(opacity=0.8,color='#00BFA5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "red_speeches_yearly = red_speeches.groupby(red_speeches['date'].dt.year)['text'].agg(['count'])\n",
    "\n",
    "# Checking grouped data\n",
    "red_speeches_yearly\n",
    "\n",
    "# Adding year column\n",
    "red_speeches_yearly['year'] = red_speeches_yearly.index\n",
    "\n",
    "# Dropping wrong year\n",
    "red_speeches_yearly = red_speeches_yearly[red_speeches_yearly['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "red_speeches_yearly['year'] = red_speeches_yearly['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(red_speeches_yearly).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('count', title='Antal taler'),\n",
    "    tooltip = 'count'\n",
    ").interactive().configure_mark(opacity=0.8,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words per speech per year: Before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column with number of words per speech\n",
    "red_speeches['no_words'] = red_speeches['text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "red_speeches_yearly_no_words = red_speeches.groupby(red_speeches['date'].dt.year)['no_words'].agg(['mean'])\n",
    "\n",
    "# Checking grouped data\n",
    "red_speeches_yearly_no_words\n",
    "\n",
    "# Adding year column\n",
    "red_speeches_yearly_no_words['year'] = red_speeches_yearly_no_words.index\n",
    "\n",
    "# Dropping wrong year\n",
    "red_speeches_yearly_no_words = red_speeches_yearly_no_words[red_speeches_yearly_no_words['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "red_speeches_yearly_no_words['year'] = red_speeches_yearly_no_words['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(red_speeches_yearly_no_words).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('mean', title='Antal ord'),\n",
    "    tooltip = 'mean'\n",
    ").interactive().configure_mark(opacity=0.8,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blue Parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "blue_speeches_yearly = blue_speeches.groupby(blue_speeches['date'].dt.year)['text'].agg(['count'])\n",
    "\n",
    "# Checking grouped data\n",
    "blue_speeches_yearly\n",
    "\n",
    "# Adding year column\n",
    "blue_speeches_yearly['year'] = blue_speeches_yearly.index\n",
    "\n",
    "# Dropping wrong year\n",
    "blue_speeches_yearly = blue_speeches_yearly[blue_speeches_yearly['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "blue_speeches_yearly['year'] = blue_speeches_yearly['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(blue_speeches_yearly).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('count', title='Antal taler'),\n",
    "    tooltip = 'count'\n",
    ").interactive().configure_mark(opacity=0.8,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words per speech per year: Before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column with number of words per speech\n",
    "blue_speeches['no_words'] = blue_speeches['text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "blue_speeches_yearly_no_words = blue_speeches.groupby(blue_speeches['date'].dt.year)['no_words'].agg(['mean'])\n",
    "\n",
    "# Checking grouped data\n",
    "blue_speeches_yearly_no_words\n",
    "\n",
    "# Adding year column\n",
    "blue_speeches_yearly_no_words['year'] = blue_speeches_yearly_no_words.index\n",
    "\n",
    "# Dropping wrong year\n",
    "blue_speeches_yearly_no_words = blue_speeches_yearly_no_words[blue_speeches_yearly_no_words['year'] < 2021]\n",
    "\n",
    "# Turning into interger and then string\n",
    "blue_speeches_yearly_no_words['year'] = blue_speeches_yearly_no_words['year'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pltotting the speeches\n",
    "alt.Chart(blue_speeches_yearly_no_words).mark_bar().encode(\n",
    "    x=alt.X('year', title=''),\n",
    "    y=alt.Y('mean', title='Antal ord'),\n",
    "    tooltip = 'mean'\n",
    ").interactive().configure_mark(opacity=0.8,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data sets for different policy areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Udvælger de relevante policy emner. Læs op på dette. Gerne artikel om værdi- og fordelingspolitik. Tjek Flemming Christiansen artikel.\n",
    "2. Kig 1000 taler igennem og fordel ord, som passer ind i de forskellige kategorier, så der er ene ordbog for alle emner.\n",
    "3. Subset data og lav pickles for alle data filer. (4x3 - rød_4, blå_4, alle_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tjek denne tale i datasættet:\n",
    "337476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting 1000 random speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "speeches = pd.read_pickle(\"all_speeches.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting DF\n",
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting 1000 random speeches\n",
    "random_speeches = speeches.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting random speeches\n",
    "random_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading each speeches\n",
    "print(random_speeches.iloc[499,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Udlændingepolitik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "udlændingpolitisk_ordbog = ['statsborgerskab',\n",
    "                            'opholdstilladelse',\n",
    "                            'integration',\n",
    "                            'flygtnininge',\n",
    "                            'indvandrere',\n",
    "                            'tosprogede',\n",
    "                            'udlændinge',\n",
    "                            'islam',\n",
    "                            'imamer',\n",
    "                            'parallelsamfund',\n",
    "                            'asylpolitik',\n",
    "                            'integrationspolitik',\n",
    "                            'udlændingepolitik',\n",
    "                            'flygtningepolitik',\n",
    "                            'asylpolitisk',\n",
    "                            'integrationspolitisk',\n",
    "                            'udlændingepolitisk',\n",
    "                            'flygtningepolitisk',\n",
    "                            'flygtningenævnet',\n",
    "                            'ghetto',\n",
    "                            'ghettoriseringseffekten',\n",
    "                            'ghettosering',\n",
    "                            'udlændingestyrelsen',\n",
    "                            'flygtningekonvention',\n",
    "                            'muslimer',\n",
    "                            'racehygiejne',\n",
    "                            'starthjælp',\n",
    "                            'sprogbonus',\n",
    "                            'indfødsret',\n",
    "                            'indfødsretsprøve',\n",
    "                            'udlændingepakken',\n",
    "                            'danskundervisning',\n",
    "                            'integrationsprogram',\n",
    "                            'integrationsindsats',\n",
    "                            'integrationsbarometer',\n",
    "                            'udlændingepolitikken',\n",
    "                            'migration',\n",
    "                            'muslimske',\n",
    "                            'asylpladser',\n",
    "                            'asylsøgere',\n",
    "                            'asylbørn',\n",
    "                            'integrationsplaner',\n",
    "                            'ikkevestlige',\n",
    "                            'grænsekontrol',\n",
    "                            'maskeringsforbuddet',\n",
    "                            'maskeringsforbud',\n",
    "                            'udlændingedebat',\n",
    "                            'udlændingeområdet',\n",
    "                            'flygtningestrømme',\n",
    "                            'integration',\n",
    "                            'udlændinge',\n",
    "                            'etnisk',\n",
    "                            'anden etnisk',\n",
    "                            'sharia',\n",
    "                            'masseindvandring' \n",
    "                           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klimapolitik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "klimapolitisk_ordbog = ['forurene',\n",
    "                        'klima',\n",
    "                        'klimaforandringer',\n",
    "                        'forurening',\n",
    "                        'miljøeffekt',\n",
    "                        'giftstoffer',\n",
    "                        'co2',\n",
    "                        'co2-reduktion',\n",
    "                        'grøn omstiling',\n",
    "                        'grønne omstilling',\n",
    "                        'biodiversitet',\n",
    "                        'PTX',\n",
    "                        'IPCEI',\n",
    "                        'vindmøller',\n",
    "                        'vindmølle',\n",
    "                        'grøn energi',\n",
    "                        'klimaplan',\n",
    "                        'kulbrint',\n",
    "                        'kulbrintebeskatning',\n",
    "                        'vandmiljø',\n",
    "                        'vandmiljøhandlingsplan',\n",
    "                        'gødning',\n",
    "                        'miljøskadelig',\n",
    "                        'klimaindsatsen',\n",
    "                        'vindmølle',\n",
    "                        'energi',\n",
    "                        'klimaændringer',\n",
    "                        'luftforandringer',\n",
    "                        'vandressourcer', \n",
    "                        'skovressourcer', \n",
    "                        'C02-miljøvenlig',\n",
    "                        'benzinforurening',\n",
    "                        'miljøoptimering',\n",
    "                        'miljøøkonomi',\n",
    "                        'fossilt brændstof',\n",
    "                        'fossilt brændsel',\n",
    "                        'fossile brændstoffer',\n",
    "                        'fossile brændsler',\n",
    "                        'solceller',\n",
    "                        'vindmøller',\n",
    "                        'miljøpolitik',\n",
    "                        'klimapolitik',\n",
    "                        'miljøbelastning',\n",
    "                        'miljøvenlig',\n",
    "                        'klimatiltag',\n",
    "                        'miljøpolitisk',\n",
    "                        'klimapolitisk',\n",
    "                        'klimamål',\n",
    "                        'klimakommission',\n",
    "                        'atomkraft',\n",
    "                        'fossil energi',\n",
    "                        'klimamålsætning',\n",
    "                        'klimaregulering',\n",
    "                        'miljøafgift'\n",
    "                       ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skattepolitik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skattepolitisk_ordbog = ['skattestop',\n",
    "                         'skattehuller',\n",
    "                         'brugerbetaling',\n",
    "                         'skattesystemet',\n",
    "                         'skatte',\n",
    "                         'skat',\n",
    "                         'skattetrykket',\n",
    "                         'skattetryk',\n",
    "                         'beskatning',\n",
    "                         'skattevæsenet',\n",
    "                         'moms',\n",
    "                         'skattereform',\n",
    "                         'skatterabat',\n",
    "                         'topskatten',\n",
    "                         'fradrag',\n",
    "                         'skatteyder',\n",
    "                         'topskatteyder',\n",
    "                         'jobfradrag',\n",
    "                         'skattenedsættelse',\n",
    "                         'skattekontrolloven',\n",
    "                         'SKAT',\n",
    "                         'skatteudvalget',\n",
    "                         'kommuneskat',\n",
    "                         'skatteprocent',\n",
    "                         'skattekort',\n",
    "                         'trækprocent',\n",
    "                         'beskatningsgrundlaget',\n",
    "                         'skatterådet',\n",
    "                         'skattebelagt',\n",
    "                         'skatteministeren',\n",
    "                         'ubeskattet',\n",
    "                         'afgifter',\n",
    "                         'gebyrer',\n",
    "                         'udligningsskatten',\n",
    "                         'skattelettelse',\n",
    "                         'skatteudspil',\n",
    "                         'skattefri',\n",
    "                         'skatteforslag',\n",
    "                         'skatteaftalen',\n",
    "                         'topskattelettelser',\n",
    "                         'sambeskatningsordningen',\n",
    "                         'skattestoppet',\n",
    "                         'momsregistrerede',\n",
    "                         'momsregnskab',\n",
    "                         'skatteværdi',\n",
    "                         'skattepligtige',\n",
    "                         'skattepolitik',\n",
    "                         'skattepolitisk',\n",
    "                         'skatteløsninger',\n",
    "                         'skattely'\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velfærdspolitik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "velfærdpolitisk_ordbog = ['velfærdsreformer',\n",
    "                          'efterløn',\n",
    "                          'dagpasning',\n",
    "                          'dagpenge',\n",
    "                          'mindsteløn',\n",
    "                          'ulighed',\n",
    "                          'arbejdsløs',\n",
    "                          'aktivering'\n",
    "                          'pension',\n",
    "                          'offentlige ydelser',\n",
    "                          'førtidspension',\n",
    "                          'kontanthjælp',\n",
    "                          'kontanthjælpsloft',\n",
    "                          'kontanthjælpsniveau',\n",
    "                          'velfærd',\n",
    "                          'plejehjem',\n",
    "                          'børnehaver',\n",
    "                          'børnehave'\n",
    "                          'folkeskoler',\n",
    "                          'folkeskolen',\n",
    "                          'velfærdssamfund',\n",
    "                          'overenskomst',\n",
    "                          'dagpengesystem',\n",
    "                          'velfærdssystem',\n",
    "                          'hjemmehjælp',\n",
    "                          'forsøgelse',\n",
    "                          'forsøgelsesgrundlag',\n",
    "                          'folkepension',\n",
    "                          'arbejdsmarkedet',\n",
    "                          'ældre',\n",
    "                          'beskæftigelse',\n",
    "                          'arbejdsmarkedskøen',\n",
    "                          'fattigdom',\n",
    "                          'beskæftigelse',\n",
    "                          'flexicurity',\n",
    "                          'velfærdsydelser',\n",
    "                          'børnecheck',\n",
    "                          'ældrechecken',\n",
    "                          'kernevelfærden',\n",
    "                          'kernevelfærd',\n",
    "                          'servicelovens',\n",
    "                          'kerneydelser',\n",
    "                          'velfærdspolitik',\n",
    "                          'velfærdspolitisk',\n",
    "                          'bistandshjælp',\n",
    "                          'dagpengeniveau',\n",
    "                          'dagpengeperiode'\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "udlændingpolitisk_ordbog_nodup = list(dict.fromkeys(udlændingpolitisk_ordbog))\n",
    "klimapolitisk_ordbog_nodup = list(dict.fromkeys(klimapolitisk_ordbog))\n",
    "skattepolitisk_ordbog_nodup = list(dict.fromkeys(skattepolitisk_ordbog))\n",
    "velfærdpolitisk_ordbog_nodup = list(dict.fromkeys(velfærdpolitisk_ordbog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data sets\n",
    "all_speeches = pd.read_pickle('all_speeches_notfidf.pkl')\n",
    "#blue_speeches = pd.read_pickle('blue_speeches.pkl')\n",
    "#red_speeches = pd.read_pickle('red_speeches.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dfs\n",
    "all_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case that speeches\n",
    "all_speeches['full_text'] = all_speeches['full_text'].str.lower()\n",
    "#blue_speeches['full_text'] = blue_speeches['full_text'].str.lower()\n",
    "#red_speeches['full_text'] = red_speeches['full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating regex for word serach\n",
    "pattern_udlændinge = '|'.join(udlændingpolitisk_ordbog_nodup)\n",
    "pattern_klima = '|'.join(klimapolitisk_ordbog_nodup)\n",
    "pattern_skatte = '|'.join(skattepolitisk_ordbog_nodup)\n",
    "pattern_velfærd = '|'.join(velfærdpolitisk_ordbog_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns\n",
    "speeches['udlændinge_pol'] = speeches['full_text'].str.contains(pattern_udlændinge)\n",
    "#blue_speeches['udlændinge_pol'] = blue_speeches['full_text'].str.contains(pattern_udlændinge)\n",
    "#red_speeches['udlændinge_pol'] = red_speeches['full_text'].str.contains(pattern_udlændinge)\n",
    "\n",
    "speeches['klima_pol'] = speeches['full_text'].str.contains(pattern_klima)\n",
    "#blue_speeches['klima_pol'] = blue_speeches['full_text'].str.contains(pattern_klima)\n",
    "#red_speeches['klima_pol'] = red_speeches['full_text'].str.contains(pattern_klima)\n",
    "\n",
    "speeches['skatte_pol'] = speeches['full_text'].str.contains(pattern_skatte)\n",
    "#blue_speeches['skatte_pol'] = blue_speeches['full_text'].str.contains(pattern_skatte)\n",
    "#red_speeches['skatte_pol'] = red_speeches['full_text'].str.contains(pattern_skatte)\n",
    "\n",
    "speeches['velfærd_pol'] = speeches['full_text'].str.contains(pattern_velfærd)\n",
    "#blue_speeches['velfærd_pol'] = blue_speeches['full_text'].str.contains(pattern_velfærd)\n",
    "#red_speeches['velfærd_pol'] = red_speeches['full_text'].str.contains(pattern_velfærd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of col\n",
    "all_cols = all_speeches.columns.tolist()\n",
    "blue_cols = blue_speeches.columns.tolist()\n",
    "red_cols = red_speeches.columns.tolist()\n",
    "\n",
    "# Setting up list of cols in right order\n",
    "all_cols = all_cols[-4:] + all_cols[:-4]\n",
    "blue_cols = blue_cols[-4:] + blue_cols[:-4]\n",
    "red_cols = red_cols[-4:] + red_cols[:-4]\n",
    "\n",
    "# Creating df with right order\n",
    "all_speeches = all_speeches[all_cols]\n",
    "blue_speeches = blue_speeches[blue_cols]\n",
    "red_speeches = red_speeches[red_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udlændinge_pol\n",
      "False    1740307\n",
      "True       79440\n",
      "Name: udlændinge_pol, dtype: int64\n",
      "\n",
      " klima_pol\n",
      "False    1751863\n",
      "True       67884\n",
      "Name: klima_pol, dtype: int64\n",
      "\n",
      " skatte_pol\n",
      "False    1669430\n",
      "True      150317\n",
      "Name: skatte_pol, dtype: int64\n",
      "\n",
      " velfærd_pol\n",
      "False    1477113\n",
      "True      342634\n",
      "Name: velfærd_pol, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('udlændinge_pol')\n",
    "print(speeches['udlændinge_pol'].value_counts())\n",
    "#print(blue_speeches['udlændinge_pol'].value_counts())\n",
    "#print(red_speeches['udlændinge_pol'].value_counts())\n",
    "\n",
    "print('\\n klima_pol')\n",
    "print(speeches['klima_pol'].value_counts())\n",
    "#print(blue_speeches['klima_pol'].value_counts())\n",
    "#print(red_speeches['klima_pol'].value_counts())\n",
    "\n",
    "print('\\n skatte_pol')\n",
    "print(speeches['skatte_pol'].value_counts())\n",
    "#print(blue_speeches['skatte_pol'].value_counts())\n",
    "#print(red_speeches['skatte_pol'].value_counts())\n",
    "\n",
    "print('\\n velfærd_pol')\n",
    "print(speeches['velfærd_pol'].value_counts())\n",
    "#print(blue_speeches['velfærd_pol'].value_counts())\n",
    "#print(red_speeches['velfærd_pol'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches.to_pickle(\"all_speeches.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_speeches[all_speeches['klima_pol']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[402,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pickles\n",
    "all_speeches.to_pickle(\"all_speeches_notfidf.pkl\")\n",
    "\n",
    "#blue_speeches.to_pickle(\"blue_speeches.pkl\")\n",
    "\n",
    "#red_speeches.to_pickle(\"red_speeches.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "count = 1\n",
    "for column in red_speeches.columns:\n",
    "    if column == 'blok':\n",
    "        cols.append(f'blok{count}')\n",
    "        count+=1\n",
    "        continue\n",
    "    cols.append(column)\n",
    "red_speeches.columns = cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_speeches.drop(['blok2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_speeches.rename(columns={'blok1': 'blok'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_speeches['blok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
